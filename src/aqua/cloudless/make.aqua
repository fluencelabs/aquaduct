aqua Cloudless_Make declares *

import PeerId, Op from "@fluencelabs/aqua-lib/builtin.aqua"
import Subnet, Worker from "@fluencelabs/aqua-lib/subnet.aqua"
import Worker as WLibW from "@fluencelabs/aqua-lib/workers.aqua"
import pushAll, optOr, contains from "../utils"
import Function, DealId from "core"

import Error, Promise from "../promise"
import Job, j_timeout from "../job"
-- use timeout from "job" as Job
use done from "../promise" as Promise
import Compute from "../compute"
import Yield from "yield"
import Logger, prefixed_log from "../logger"

func resolveSubnet{Logger}(deal_id: DealId, errors: *Error) -> []Worker:
  subnet <- Subnet.resolve(deal_id)
  Logger.log(["resolveSubnet", "subnet=", subnet])
  workers: *Worker
  if subnet.success == false:
    Logger.log(["Subnet resolve failed"])
    errors <<- "Subnet resolve failed"
  else:
    -- cannot use pushAll as it's typed with string
    for w <- subnet.workers:
      workers <<- w
  <- workers

func simple{Compute, Logger}(coordinator: ?PeerId, yield: Yield) -> Function:
  log = Logger.log

  deal_run = func (deal_id: DealId) -> Job:
    ok: *string
    -- TODO errors: %Error
    errors: *Error

    run = func (promise: Promise) -> Promise:
      -- moves :(
      host <- optOr(coordinator, HOST_PEER_ID)

      workers: *Worker
      on host:
        subn <- resolveSubnet{Logger}(deal_id, errors)
      log(["Subnet is resolved", subn])       
      parseq w <- subn on w.worker_id! via w.host_id via host:
        is_active_opt: *bool
        on w.host_id:
          try:
            is_active_opt <- WLibW.is_active(deal_id)
          catch e:
            errors <<- e.message
            is_active_opt <<- false

        is_active = is_active_opt!
        log(["Hello guys!", is_active, w.host_id])
        if is_active == false:
          log(["Deal is inactive on this host, have you deposited enough funds?", w.host_id])
          errors <<- "Deal is not active, worker is not created or not available"
        else:
          log(["Deal is active, okay"])

          log(["Going go ", w.worker_id!, "via", w.host_id])
          
          job <- Compute.job(w)
          log(["got compute job on", w.worker_id!])
          try:
            job.run(promise)
            log(["Going to add a worker to done workers"])
            workers <<- w
          catch e:
            log(["Compute job errored on", w.worker_id!, "message:", e.message])
            errors <<- e.message

      c_yield = func (w: Worker) -> ?Error:
        <- Compute.yield(w)

      new_yield = func () -> ?Error:
        log(["Running new yield"])
        y <- yield(workers, errors, c_yield)
        new_errs <- y.yield()
        log(["YIELDED WHAT?!!", new_errs])
        <- new_errs
      <- Promise(yield = new_yield)

    <- Job(run = run)
  <- Function(run = deal_run)

-- Executor must make sure that job is running on a host
func simple2{Compute, Logger}(yield: Yield) -> Function:
  log = prefixed_log{Logger}("Make.simple2")

  deal_run = func (deal_id: DealId) -> Job:
    workers: *Worker
    errors: *Error
    run = func (promise: Promise) -> Promise:
      subn <- resolveSubnet{Logger}(deal_id, errors)

      for w <- subn par:
       on w.worker_id! via w.host_id:
        j <- Compute.job(w)
        j.run(promise)
        workers <<- w

      new_yield = func () -> ?Error:
        log(["Running new yield"])
        y <- yield(workers, errors, Compute.yield)
        new_errs <- y.yield()
        log(["new_errs =", new_errs])
        <- new_errs
      <- Promise(yield = new_yield)

    <- Job(run = run)
  <- Function(run = deal_run)        

-- Compute: will be triggered on every worker that could be reached.
--        If subnet-scale coordination is needed, Compute must conduct it
-- peers: list of peer ids to build disjoint paths
-- deal_id: subnet to run Compute on
-- yield: will run on every peer, should determine when there's enough results from different workers
func disjoint{Compute, Logger}(peers: []PeerId, yield: Yield) -> Function:
  log = Logger.log

  errors: *Error

  -- Path to worker
  ingoing: *PeerId
  -- path to and from worker
  outgoing: *[]PeerId

  -- Stream of workers that did the job
  workers: *Worker

  -- Internal: mutex to run job on every peer only once
  observed_on: *PeerId

  deal_run = func (deal_id: DealId) -> Job:

    run = func (promise: Promise) -> Promise:
      parseq p <- peers on p:
        -- Yield previous job on different peers
        -- TODO should we yield it on workers instead? I think we don't
        prev_err <- promise.yield()
        pushAll(errors, prev_err)

        -- Independent resolve on every peer -- triggers moving to p
        p_workers <- resolveSubnet{Logger}(deal_id, errors)

        -- Remember the peer: it should be the first local write to ingoing
        ingoing <<- p

        -- TODO: handle failures, e.g. with timeouts?
        -- So now we go many times from intermediary peer p to every worker
        -- We cannot do it outside of parseq, as we need access to res.workers without implicit canonicalization
        parseq w <- p_workers on w.host_id:
          log(["on host", w.host_id])
          -- Run job only once on every peer
          if contains(observed_on, w.worker_id!) == false:
              -- This peer was reached via another peer
              log(w.worker_id)
              observed_on <<- w.worker_id!
              -- Job is initiated only once on every peer
              log([w.worker_id!, "Get Compute.job"])
              job <- Compute.job(w)
              log([w.worker_id!, "Job planned"])

              -- Cannot use the value :( but do run the job
              pr <- job.run(Promise.done())
              log([w.worker_id!, "Got a Promise"])

              -- Workers is a stream of workers that have the job triggered/scheduled
              workers <<- w
          else:
            log(["Worker was already visited", w.worker_id!])

      parseq p <- peers on p:
        -- Independently, need to wait for the required number of workers to succeed before proceeding
        c_yield = func (w: Worker) -> ?Error:
          <- Compute.yield(w)
        log(["on parsec ABOUT TO YIELD", p])  
        y <- yield(workers, errors, c_yield)
        pushAll(errors, y.yield())
        log(["Yielded on workers", p])
        -- fastest ingoing, this outgoing
        outgoing <<- [ingoing!, p]

      new_yield = func () -> ?Error:
        -- This is the fastest path, but we have no place to keep it
        log(["New yield"])
        join outgoing!
        log(["Joined"])
        <- nil

      <- Promise(yield = new_yield)

    <- Job(run = run)
  <- Function(run = deal_run)