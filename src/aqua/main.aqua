aqua Main

import "@fluencelabs/aqua-lib/builtin.aqua"
import "@fluencelabs/aqua-lib/subnet.aqua"

use "deals.aqua"
use "hosts.aqua"
import "services.aqua"

use "cloudless/make"
use "cloudless/exec"
use "cloudless/yield"

use "compute"
import Error from "promise"
import local as make_logger, prefixed_log from "logger"
import prepend from "utils"


-- DOCUMENTATION:
-- https://fluence.dev


export cloudless

-- Mind the return type: it could be different
func cloudless() -> []string:
  --
  -- Read deal info from configuration â€“ need to deploy first
  --
  deals <- Deals.get()
  dealId = deals.myDeployment!.dealId

  --
  -- Prepare logging for debugability
  --

  logger = make_logger(true)

  --
  -- Express your compute function
  --

  -- Append-only accumulator of results that all our subnet workers will write to.
  -- Not necessarily a string.
  res: *string

  -- Inside this closure, express what should happen on your worker (that's given as an argument).
  -- All your services are available here. And builtin ones.
  -- If you need time or such things, do a short hop to w.host_id.
  start = func (w: Worker):
    wlog = prefixed_log{logger}("W.start")

    wlog([w.worker_id!, "About to start working"])
    r <- MyService.greeting("-works-ok-")
    wlog([w.worker_id!, "MyService.greeting", r])
    res <<- r
        

  -- This closure is to find out whether given worker completed the job
  -- Like, find worker_id in res stream, join on the result (to trigger waiting)...
  -- Or return errors
  yield = func (w: Worker) -> ?Error:
    logger.log(["W.yield", w.worker_id!, "About to join res!"])
    join res!
    -- TODO: find this worker in res...
    <- nil

  -- Finally, build your compute function from start and yield closures
  comp = Compute.lift(start, yield)

  --
  -- Make Cloudless Function
  --

  -- First, we make a cloudless function that will have our compute function executed on the workers.
  -- Simple and disjoint both call function on all workers in parallel.
  -- Disjoint can be used to protect from censoring your subnet by getting to subnet workers through disjoint paths.
  -- Simple resolves the subnet on a single given peer, or, if omitted, on the relay.
  -- Cloudless_Yield.wait_for_k will wait for this number of responses before considering success.
  --fn = Cloudless_Make.simple{comp, logger}(Cloudless_Yield.wait_for{logger}(2, 1))
  fn = Cloudless_Make.disjoint{comp, logger}([HOST_PEER_ID], Cloudless_Yield.wait_for{logger}(1, 1))

  --
  -- Execute Cloud Function
  --

  -- Here we do a roundtrip, which means that we will get the result back to us.
  -- Another option is fireAndForget. In this case, you should not expect any result returned to you.
  -- First argument is your deal id to resolve the deployed subnet.
  -- Second argument is where the function will yield. It's more efficient to do it on HOST_PEER_ID, but can do it on INIT_PEER_ID if you like.
  Console.print(["Execution begins now"])
  errs <- Cloudless_Exec.roundtrip{fn, logger}(dealId, ?[HOST_PEER_ID])
  --Console.print(["Errors after roundtrip:", errs])

  if errs != nil:
    new_errs <- prepend("Errors:", errs)
    Console.print(new_errs)

  -- Results are collected into your res variable. Now it should be ready to use, filled with values.
  -- Please note that errors handling is ignored in this example, which may hurt in the real life.
  <- res
