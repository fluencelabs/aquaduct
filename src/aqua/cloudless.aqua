aqua Cloudless declares Function, roundtrip, fireAndForget, disjoint_run, wait_for_k, cl_timeout

import "@fluencelabs/aqua-lib/builtin.aqua"
import "@fluencelabs/aqua-lib/subnet.aqua"
import "utils"

import Error, Promise from "promise"
import Job, j_timeout from "job"
-- use timeout from "job" as Job
use done from "promise" as Promise
import Compute from "compute"

alias DealId : string

-- Cloudless Function runs Compute on a single Subnet â€“ with the given execution policy
ability Function:
  run(dealId: DealId) -> Job

--
-- SIMPLE EXECUTORS
--

-- Request, response roundtrip
func roundtrip{Function}(dealId: DealId, yieldOnPeer: ?string) -> ?Error:
  yieldOn: *string
  pushAll(yieldOn, yieldOnPeer)
  yieldOn <<- HOST_PEER_ID

  on yieldOn!:
    -- Next two lines should do nothing on yieldOn peer
    job <- Function.run(dealId)
    promise <- job.run(Promise.done())

    -- This should actually happen with move to yieldOn
    err <- promise.yield()

  <- err

-- Fire a request, no topology hops back to init peer should happen
func fireAndForget{Function}(dealId: DealId):
  run = ():
    job <- Function.run(dealId)
    job.run(Promise.done())
  co run()  

--
-- DECORATORS
--

-- Function times out and errors after ms
-- Checked on yield phase
-- TODO should be just timeout, but imports work poorly
func cl_timeout{Function}(waitForMs: u64, errorMessage: Error) -> Function:
  run = func(dealId: DealId) -> Job:
    j <- Function.run(dealId)
    <- j_timeout{j}(waitForMs, errorMessage)

  <- Function(run = run)

--
-- Strategies for Cloudless Functions
--

-- Wait for K replies, no matter the quality of replies, success/err
func wait_for_k(k: u8) -> (*Worker -> Promise):
  wait = func (ws: *Worker) -> Promise:
    yield = func () -> ?Error:
      join ws[k-1]
      <- nil
    <- Promise(yield = yield)
  <- wait    

-- Compute: will be triggered on every worker that could be reached. 
--        If subnet-scale coordination is needed, Compute must conduct it
-- peers: list of peer ids to build disjoint paths
-- deal_id: subnet to run Compute on
-- yield: will run on every peer, should determine when there's enough results from different workers
func disjoint_run{Compute}(peers: []PeerId, yield: *Worker -> Promise, log: []string -> ()) -> Function:
  -- Path to worker
  ingoing: *PeerId
  -- path to and from worker
  outgoing: *[]PeerId

  -- Stream of workers that did the job
  workers: *Worker

  -- Internal: mutex to run job on every peer only once
  observed_on: *PeerId

  deal_run = func (deal_id: DealId) -> Job:

    run = func (promise: Promise) -> Promise:
        parseq p <- peers on p:
            -- Yield previous job on different peers
            -- TODO should we yield it on workers instead? I think we don't
            prev <- promise.yield()
            -- TODO: consider the error!
            -- log(prev)
            log(["Resolving subnet at:", p])

            -- Independent resolve on every peer -- triggers moving to p
            res <- Subnet.resolve(deal_id)

            -- Remember the peer: it should be the first local write to ingoing
            ingoing <<- p

            -- TODO: handle failures, e.g. with timeouts?
            -- So now we go many times from intermediary peer p to every worker
            -- We cannot do it outside of parseq, as we need access to res.workers without implicit canonicalization
            parseq w <- res.workers on w.host_id:
                co log(["on host", w.host_id])
                -- Run job only once on every peer
                if contains(observed_on, w.worker_id!) == false:
                    -- This peer was reached via another peer
                    log(w.worker_id)
                    observed_on <<- w.worker_id!
                    -- Job is initiated only once on every peer
                    log([w.worker_id!, "Get Compute.job"])
                    job <- Compute.job(w)
                    log([w.worker_id!, "Job planned"])

                    -- Cannot use the value :( but do run the job
                    pr <- job.run(Promise.done())
                    log([w.worker_id!, "Got a Promise"])
                
                    -- TODO: temporary shit
                    z <- pr.yield()
                    log([w.worker_id!, "Promise yielded"])
                    log(z)

                    -- Workers is a stream of workers that have the job triggered/scheduled
                    workers <<- w
                else:
                  log(["Worker was already visited", w.worker_id!])

        parseq p <- peers on p:
            -- Independently, need to wait for the required number of workers to succeed before proceeding
            y <- yield(workers)
            y.yield()
            co log(["Yielded on workers", p])
            -- fastest ingoing, this outgoing
            outgoing <<- [ingoing!, p]
        
        new_yield = func () -> ?Error:
            -- This is the fastest path, but we have no place to keep it
            co log(["New yield"])
            join outgoing!
            co log(["Joined"])
            <- nil

        <- Promise(yield = new_yield)  

    <- Job(run = run)  
  <- Function(run = deal_run)  